{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orginal Notebook Created by CIEP / Global DDM COE\n",
    "#### Nidhi Sawhney, Stojan Maleschlijski & Ian Henry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i049374/anaconda/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.models import load_model, Sequential, Model\n",
    "from keras.layers import Embedding, InputLayer, Convolution1D, MaxPooling1D, SpatialDropout1D\n",
    "from keras.layers.core import Flatten,Dense,Dropout\n",
    "\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)\n",
    "K.set_learning_phase(0)  # all new operations will be in test mode from now on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing function that expects a string of words as Ints seperated by spaces\n",
    "def preprocess (txt_input):\n",
    "    sparse_tokenized_input = tf.string_split(txt_input,delimiter=' ')\n",
    "    tokenized_input = tf.sparse_tensor_to_dense(sparse_tokenized_input, default_value='0')\n",
    "    token_idxs = tf.string_to_number(tokenized_input, out_type=tf.float32)\n",
    "    inputlength = tf.size(token_idxs)\n",
    "    # Max Number of Words in Sentance 40\n",
    "    padding = 40 - inputlength\n",
    "    token_idxs_padded = tf.pad(token_idxs, [[0,0],[padding,0]])\n",
    "    token_idxs_embedding = tf.slice(token_idxs_padded, [0,0], [1,40])\n",
    "    return token_idxs_embedding;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the Keras Model\n",
    "model = load_model('./Models/FakeNews-v7.h5')\n",
    "\n",
    "txt_input = tf.placeholder(tf.string, name='txt_input')\n",
    "token_idxs_embedding = preprocess(txt_input)\n",
    "\n",
    "# Recreate Binary Classification Model\n",
    "text_fn_model = Sequential([\n",
    "    InputLayer(input_tensor=token_idxs_embedding,input_shape=(1,40)),\n",
    "    Embedding(5000, 32, input_length=40),\n",
    "    SpatialDropout1D(0.2),\n",
    "    Dropout(0.25),\n",
    "    Convolution1D(64, 5, padding='same', activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    MaxPooling1D(),\n",
    "    Flatten(),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.7),\n",
    "    Dense(1, activation='sigmoid',name='prediction')])\n",
    "\n",
    "text_fn_model.name='fakenews'\n",
    "config = model.get_config()\n",
    "weights = model.get_weights()\n",
    "text_fn_model.set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'./Models/FakeNews-Serving/1/saved_model.pb'\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.saved_model import builder as saved_model_builder\n",
    "from tensorflow.python.saved_model import utils\n",
    "from tensorflow.python.saved_model import tag_constants, signature_constants\n",
    "from tensorflow.python.saved_model.signature_def_utils_impl import build_signature_def, predict_signature_def\n",
    "from tensorflow.contrib.session_bundle import exporter\n",
    "\n",
    "# You must increment the number below if you run this.  This is the Model version for Serving\n",
    "export_path = './Models/FakeNews-Serving/1'\n",
    "builder = saved_model_builder.SavedModelBuilder(export_path)\n",
    "\n",
    "signature = predict_signature_def(inputs={'text': txt_input},\n",
    "                               outputs={'labels': text_fn_model.output})\n",
    "\n",
    "with K.get_session() as sess:\n",
    "    builder.add_meta_graph_and_variables(sess=sess, tags=[tag_constants.SERVING],\n",
    "                                        signature_def_map={signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: signature})\n",
    "    builder.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
